{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLIllFuSv-Sw",
        "outputId": "42740a90-eef9-4c56-a747-1824e2af22fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ],
      "source": [
        "# Check PyTorch version installed on this system\n",
        "!python -c \"import torch; print(torch.__version__)\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Download the corresponding PyTorch Geometric module\n",
        "\"\"\"\n",
        "Assign to TORCH with what you get from the cell above. E.g., export TORCH=1.12.1+cu113\n",
        "\"\"\"\n",
        "%env TORCH=2.1.0+cu121\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "wj4gIIEdxY_w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.utils import from_networkx\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import Sequential, GCNConv, global_mean_pool\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "rng = np.random.default_rng()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfU64gKTxZo1",
        "outputId": "33665bed-2300-4def-923e-5315e1520a6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, Optional, Union\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.nn.dense.linear import Linear\n",
        "from torch_geometric.nn.inits import reset\n",
        "from torch_geometric.typing import (\n",
        "    Adj,\n",
        "    OptPairTensor,\n",
        "    OptTensor,\n",
        "    Size,\n",
        "    SparseTensor,\n",
        ")\n",
        "from torch_geometric.utils import spmm\n",
        "\n",
        "class GINConv(MessagePassing):\n",
        "  def __init__(self, nn_final: Callable, nn_intermediate_self: Callable, nn_intermediate_sum: Callable, eps: float = 0., train_eps: bool = False,\n",
        "                 **kwargs):\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(**kwargs)\n",
        "        self.nn_final = nn_final\n",
        "        self.nn_intermediate_self = nn_intermediate_self\n",
        "        self.nn_intermediate_sum = nn_intermediate_sum\n",
        "        self.initial_eps = eps\n",
        "        if train_eps:\n",
        "            self.eps = torch.nn.Parameter(torch.empty(1))\n",
        "        else:\n",
        "            self.register_buffer('eps', torch.empty(1))\n",
        "        self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "        super().reset_parameters()\n",
        "        reset(self.nn_final)\n",
        "        reset(self.nn_intermediate_self)\n",
        "        reset(self.nn_intermediate_sum)\n",
        "        self.eps.data.fill_(self.initial_eps)\n",
        "\n",
        "\n",
        "  def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
        "                size: Size = None) -> Tensor:\n",
        "\n",
        "        if isinstance(x, Tensor):\n",
        "            x: OptPairTensor = (x, x)\n",
        "\n",
        "        # propagate_type: (x: OptPairTensor)\n",
        "        out = self.propagate(edge_index, x=x, size=size)\n",
        "\n",
        "        x_r = x[1]\n",
        "        if x_r is not None:\n",
        "            out = out + (1 + self.eps) * self.nn_intermediate_self(x_r)\n",
        "\n",
        "        return self.nn_final(out)\n",
        "\n",
        "\n",
        "  def message(self, x_j: Tensor) -> Tensor:\n",
        "      return self.nn_intermediate_sum(x_j)\n",
        "\n",
        "class OtherConv(MessagePassing):\n",
        "  def __init__(self, nn_final: Callable, nn_intermediate_self: Callable, nn_intermediate_sum: Callable, eps: float = 0., train_eps: bool = False,\n",
        "                 **kwargs):\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(**kwargs)\n",
        "        self.nn_final = nn_final\n",
        "        self.nn_intermediate_self = nn_intermediate_self\n",
        "        self.nn_intermediate_sum = nn_intermediate_sum\n",
        "        self.initial_eps = eps\n",
        "        if train_eps:\n",
        "            self.eps = torch.nn.Parameter(torch.empty(1))\n",
        "        else:\n",
        "            self.register_buffer('eps', torch.empty(1))\n",
        "        self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "        super().reset_parameters()\n",
        "        reset(self.nn_final)\n",
        "        reset(self.nn_intermediate_self)\n",
        "        reset(self.nn_intermediate_sum)\n",
        "        self.eps.data.fill_(self.initial_eps)\n",
        "\n",
        "\n",
        "  def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
        "                size: Size = None) -> Tensor:\n",
        "\n",
        "        if isinstance(x, Tensor):\n",
        "            x: OptPairTensor = (x, x)\n",
        "\n",
        "        # propagate_type: (x: OptPairTensor)\n",
        "        out = self.propagate(edge_index, x=x, size=size)\n",
        "\n",
        "        x_r = x[1]\n",
        "        if x_r is not None:\n",
        "            out = self.nn_intermediate_sum(out) + (1 + self.eps) * self.nn_intermediate_self(x_r)\n",
        "\n",
        "        return self.nn_final(out)\n",
        "\n",
        "\n",
        "  def message(self, x_j: Tensor) -> Tensor:\n",
        "      return x_j\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a5vDf6781_AU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GINLayer(nn.Module):\n",
        "  def __init__(self, input_dim, intermediate_dim, output_dim, final_mlp_structure, intermediate_self_mlp_structure, intermediate_sum_mlp_structure, activation=nn.ReLU()):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.intermediate_dim = intermediate_dim\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    self.intermediate_self_mlp = self.generate_mlp(intermediate_self_mlp_structure,input_dim,intermediate_dim,activation)\n",
        "    self.intermediate_sum_mlp = self.generate_mlp(intermediate_sum_mlp_structure,input_dim,intermediate_dim,activation)\n",
        "    self.final_mlp = self.generate_mlp(final_mlp_structure,intermediate_dim,output_dim,activation)\n",
        "\n",
        "    self.gin_conv = GINConv(self.final_mlp, self.intermediate_self_mlp, self.intermediate_sum_mlp)\n",
        "\n",
        "  def generate_mlp(self, sequence, input_dim, output_dim, activation):\n",
        "    mlp = [nn.Linear(input_dim, sequence[0], bias=False), activation]\n",
        "    for i in range(len(sequence)-1):\n",
        "      mlp.append(nn.Linear(sequence[i], sequence[i+1], bias=False))\n",
        "      mlp.append(activation)\n",
        "    mlp.append(nn.Linear(sequence[-1], output_dim, bias=False))\n",
        "    return nn.Sequential(*mlp)\n",
        "\n",
        "  def forward(self, x, adj):\n",
        "    return self.gin_conv(x, adj)\n",
        "\n",
        "class OtherLayer(nn.Module):\n",
        "  def __init__(self, input_dim, intermediate_dim, output_dim, final_mlp_structure, intermediate_self_mlp_structure, intermediate_sum_mlp_structure, activation=nn.ReLU()):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.intermediate_dim = intermediate_dim\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    self.intermediate_self_mlp = self.generate_mlp(intermediate_self_mlp_structure,input_dim,intermediate_dim,activation)\n",
        "    self.intermediate_sum_mlp = self.generate_mlp(intermediate_sum_mlp_structure,input_dim,intermediate_dim,activation)\n",
        "    self.final_mlp = self.generate_mlp(final_mlp_structure,intermediate_dim,output_dim,activation)\n",
        "\n",
        "    self.gin_conv = OtherConv(self.final_mlp, self.intermediate_self_mlp, self.intermediate_sum_mlp)\n",
        "\n",
        "  def generate_mlp(self, sequence, input_dim, output_dim, activation):\n",
        "    mlp = [nn.Linear(input_dim, sequence[0], bias=False), activation]\n",
        "    for i in range(len(sequence)-1):\n",
        "      mlp.append(nn.Linear(sequence[i], sequence[i+1], bias=False))\n",
        "      mlp.append(activation)\n",
        "    mlp.append(nn.Linear(sequence[-1], output_dim, bias=False))\n",
        "    return nn.Sequential(*mlp)\n",
        "\n",
        "  def forward(self, x, adj):\n",
        "    return self.gin_conv(x, adj)\n"
      ],
      "metadata": {
        "id": "X7SvaTRh_fEJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, model, loss_fn, optimiser):\n",
        "    \"\"\"Do one epoch-worth of training.\"\"\"\n",
        "\n",
        "    # Put the model in training mode\n",
        "    model.train()\n",
        "\n",
        "    # The number of datapoints\n",
        "    size = len(dataloader.dataset)\n",
        "\n",
        "    # Loop over each batch of datapoints\n",
        "    for graph_type in dataloader:\n",
        "        #print(graph_type)\n",
        "        # Set all the gradients to zero\n",
        "        optimiser.zero_grad()\n",
        "        preds = []\n",
        "        for graph in graph_type:\n",
        "          graph = graph.to(device)\n",
        "          # Make a prediction using the current parameters\n",
        "          preds.append(model(graph.x.to(torch.float), graph.edge_index))\n",
        "        #print(\"pred\", pred)\n",
        "        # Compute the loss for this prediction\n",
        "        loss = loss_fn(preds)\n",
        "        print(\"loss\", loss.detach().cpu().item())\n",
        "        #print(\"data.y\", data.y)\n",
        "\n",
        "        # Propagate the loss backwards to compute the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Do one step of optimisation\n",
        "        optimiser.step()\n",
        "\n",
        "def train(train_dataloader, test_dataloader, model, loss_fn, optimiser,\n",
        "          epochs=200, output_every=10):\n",
        "    \"\"\"Train a model for a certain number of epochs.\"\"\"\n",
        "    results_flag = True\n",
        "    # Loop through the epochs\n",
        "    for t in range(1, epochs+1):\n",
        "\n",
        "        # Do the training for this epoch\n",
        "        train_epoch(train_dataloader, model, loss_fn, optimiser)\n",
        "\n",
        "        # Output the accuracy of the model every so often\n",
        "\n",
        "        if output_every is not None and t % output_every == 0:\n",
        "            results = test(train_dataloader, model)\n",
        "            if results_flag:\n",
        "              best_results = [0]*len(results)\n",
        "              results_flag = False\n",
        "\n",
        "            no_graphs = [result[0] for result in results]\n",
        "            no_distinguished_list = [result[1] for result in results]\n",
        "            best_results = [max(best_result, no_distinguished) for (best_result, no_distinguished) in zip(best_results, no_distinguished_list)]\n",
        "            best_restults_percentages = [100*best_result/no_graph for (best_result, no_graph) in zip(best_results, no_graphs)]\n",
        "            print(f\"Epoch {t}\")\n",
        "            print(\"----------------------------\")\n",
        "            print(\"Accuracy: \", results)\n",
        "            print(\"Best results: \", best_results)\n",
        "            print(\"Best percentages: \", best_restults_percentages)\n",
        "            print()\n",
        "\n",
        "def test(dataloader, model):\n",
        "    \"\"\"Test a model on some data.\"\"\"\n",
        "\n",
        "    # Put the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Get the number of datapoints\n",
        "    size = len(dataloader.dataset)\n",
        "\n",
        "    # The number of correct predictions\n",
        "    correct = 0\n",
        "\n",
        "    # We don't want to be computing the gradients\n",
        "    with torch.no_grad():\n",
        "        results = []\n",
        "        # Loop through the minibatches\n",
        "        for graph_type in dataloader:\n",
        "          preds = []\n",
        "          for graph in graph_type:\n",
        "            graph = graph.to(device)\n",
        "            # Compute the model predictions\n",
        "            preds.append(model(graph.x.to(torch.float), graph.edge_index))\n",
        "          #print(preds)\n",
        "          graph_no = len(preds)\n",
        "          preds = torch.stack(preds)\n",
        "          preds = (preds*10000).round() / 10000\n",
        "          #print(preds)\n",
        "          #print(torch.unique(preds, dim=0, return_counts=True))\n",
        "          distinct_no = len(torch.unique(preds, dim=0, return_counts=True)[1])\n",
        "          results.append((graph_no, distinct_no, graph_no - distinct_no))\n",
        "\n",
        "    # Compute the accuracy for the whole dataset and return it\n",
        "    return results"
      ],
      "metadata": {
        "id": "BXTB0SeVqTov"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def criterion(embeddings):\n",
        "  counter = 0\n",
        "  cumulative_loss = 0.0\n",
        "  no_graphs = len(embeddings)\n",
        "  for i in range(no_graphs):\n",
        "    for j in range(i):\n",
        "      cumulative_loss += nn.functional.cosine_embedding_loss(embeddings[i], embeddings[j] + 0.01*torch.randn_like(embeddings[j]), torch.tensor(-1))\n",
        "      counter += 1\n",
        "\n",
        "  return cumulative_loss / counter"
      ],
      "metadata": {
        "id": "ImwWPOXDhyOF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_graphs(graph, no_feature_dicts, no_colour_1, no_colour_2, no_colour_3):\n",
        "  features = [1 for _ in range(no_colour_1)] + [2 for _ in range(no_colour_2)] + [3 for _ in range(no_colour_3)]\n",
        "  feature_dicts = []\n",
        "  for i in range(no_feature_dicts):\n",
        "    random.shuffle(features)\n",
        "    feature_dict = {i:item for (i,item) in enumerate(features)}\n",
        "    feature_dicts.append(feature_dict)\n",
        "\n",
        "  structurally_isomorphic_graphs = []\n",
        "\n",
        "  for feature_dict in feature_dicts:\n",
        "    temp_graph = graph.copy()\n",
        "    nx.set_node_attributes(temp_graph, feature_dict, name=\"colour\")\n",
        "    structurally_isomorphic_graphs.append(temp_graph)\n",
        "\n",
        "  hashes = []\n",
        "  distinguishable_graphs = []\n",
        "  for iso_graph in structurally_isomorphic_graphs:\n",
        "    hash = nx.weisfeiler_lehman_graph_hash(iso_graph,  node_attr=\"colour\", iterations=3, digest_size=16)\n",
        "    if not(hash in hashes):\n",
        "      distinguishable_graphs.append(from_networkx(iso_graph, group_node_attrs=[\"colour\"]))\n",
        "    hashes.append(hash)\n",
        "  print(\"number of distinguishable graphs: \", len(distinguishable_graphs))\n",
        "  return (distinguishable_graphs, len(distinguishable_graphs))\n"
      ],
      "metadata": {
        "id": "mvIWhRtTI8KZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = []\n",
        "total_graphs = 0\n",
        "for i in range(10):\n",
        "  graphs, no_graphs = label_graphs(nx.dense_gnm_random_graph(6,7, seed=i),200,2,2,2)\n",
        "  dataset.append(graphs)\n",
        "  total_graphs += no_graphs\n",
        "\n",
        "print(\"total number of graphs: \", total_graphs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm0uYVKOLVLA",
        "outputId": "ca044a01-2f38-4c3f-8975-38aa9baffa8c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of distinguishable graphs:  24\n",
            "number of distinguishable graphs:  48\n",
            "number of distinguishable graphs:  27\n",
            "number of distinguishable graphs:  17\n",
            "number of distinguishable graphs:  33\n",
            "number of distinguishable graphs:  84\n",
            "number of distinguishable graphs:  51\n",
            "number of distinguishable graphs:  30\n",
            "number of distinguishable graphs:  83\n",
            "number of distinguishable graphs:  45\n",
            "total number of graphs:  442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph = nx.dense_gnm_random_graph(6,7, seed=3).copy()\n",
        "### DO NOT MODIFY\n",
        "\n",
        "# Display a random pair\n",
        "fig, axs = plt.subplots(1, 1)\n",
        "#graph = random.choice(graphs)\n",
        "\n",
        "nx.draw(graph)\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "-1uDRLCU_C5V",
        "outputId": "dd36dfa7-f411-40eb-91d8-ded1431764fd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GINConv_model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.gin_1 = GINLayer(input_dim=1, intermediate_dim=12, output_dim=1, final_mlp_structure=[5,8], intermediate_self_mlp_structure=[5,8] , intermediate_sum_mlp_structure=[5,8])\n",
        "    self.gin_2 = GINLayer(input_dim=1, intermediate_dim=16, output_dim=1, final_mlp_structure=[8,8], intermediate_self_mlp_structure=[8,8], intermediate_sum_mlp_structure=[8,8])\n",
        "    self.gin_3 = GINLayer(input_dim=1, intermediate_dim=32, output_dim=1, final_mlp_structure=[8,12], intermediate_self_mlp_structure=[8,12], intermediate_sum_mlp_structure=[8,12])\n",
        "\n",
        "    #self.output_mlp = nn.Sequential(*[nn.Linear(3,12), nn.ReLU(), nn.Linear(12,12), nn.ReLU(), nn.Linear(12,12)])\n",
        "\n",
        "  def forward(self, x, adj):\n",
        "    h1 = self.gin_1(x, adj)\n",
        "    h2 = self.gin_2(h1, adj)\n",
        "    h3 = self.gin_3(h2, adj)\n",
        "    #print(h3.size())\n",
        "    concat = torch.cat([h1,h2,h3], axis=1)\n",
        "    summed = torch.sum(concat, axis=0)\n",
        "    #print(concat.size())\n",
        "    #print(summed.size())\n",
        "    #return self.output_mlp(summed)\n",
        "    return summed\n"
      ],
      "metadata": {
        "id": "ng_HfxdjHhgk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OtherConv_model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.other_1 = OtherLayer(input_dim=1, intermediate_dim=12, output_dim=1, final_mlp_structure=[5,8], intermediate_self_mlp_structure=[5,8] , intermediate_sum_mlp_structure=[5,8])\n",
        "    self.other_2 = OtherLayer(input_dim=1, intermediate_dim=16, output_dim=1, final_mlp_structure=[8,8], intermediate_self_mlp_structure=[8,8], intermediate_sum_mlp_structure=[8,8])\n",
        "    self.other_3 = OtherLayer(input_dim=1, intermediate_dim=32, output_dim=1, final_mlp_structure=[8,12], intermediate_self_mlp_structure=[8,12], intermediate_sum_mlp_structure=[8,12])\n",
        "\n",
        "    #self.output_mlp = nn.Sequential(*[nn.Linear(1,12), nn.ReLU(), nn.Linear(12,12), nn.ReLU(), nn.Linear(12,12)])\n",
        "\n",
        "  def forward(self, x, adj):\n",
        "    h1 = self.other_1(x, adj)\n",
        "    h2 = self.other_2(h1, adj)\n",
        "    h3 = self.other_3(h2, adj)\n",
        "    #print(h3.size())\n",
        "    concat = torch.cat([h1,h2,h3], axis=1)\n",
        "    summed = torch.sum(concat, axis=0)\n",
        "    #print(concat.size())\n",
        "    #print(summed.size())\n",
        "    #return self.output_mlp(summed)\n",
        "    return summed\n"
      ],
      "metadata": {
        "id": "BJi2OWnEx27M"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = OtherConv_model().to(device)"
      ],
      "metadata": {
        "id": "SURUakjiKPBf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset\n",
        "train_dataloader = DataLoader(train_dataset, 1)\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "train(train_dataloader, train_dataloader, model, criterion, optimiser, output_every=1)"
      ],
      "metadata": {
        "id": "jbGSZ1Hq6O6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}